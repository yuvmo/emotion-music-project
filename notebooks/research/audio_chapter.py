# -*- coding: utf-8 -*-
"""audio_chapter.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FdHaOmkLKh77G3CHbiBCEebaGPQKcjrm

## Подготовка окружения

В данном ноутбуке реализуется модуль обработки аудиосообщения пользователя.
Для работы используются предобученные модели распознавания эмоций по речи и
преобразования речи в текст.
"""

!pip install -q transformers librosa soundfile openai-whisper

import librosa
import numpy as np
import soundfile as sf

"""## Загрузка и ресемплинг аудиофайла

На текущем этапе аудиосообщение пользователя передаётся в виде файла.
Аудиосигнал приводится к частоте дискретизации 16 кГц для корректной
работы используемых моделей.
"""

AUDIO_PATH = "/content/silents.wav"

audio, sr = librosa.load(AUDIO_PATH, sr=16000)

print("Sample rate:", sr)
print("Duration (sec):", len(audio) / sr)

"""## Валидация аудиосообщения

Перед дальнейшей обработкой аудиосообщение проверяется на корректность.
Отбрасываются записи, содержащие только тишину, слишком короткие записи
и записи с чрезмерным уровнем шума.
"""

def is_silent(audio, threshold=0.003, min_ratio=0.05):
    rms = librosa.feature.rms(y=audio)[0]
    speech_ratio = (rms > threshold).mean()
    return speech_ratio < min_ratio

def is_too_short(audio, sr, min_duration=1.0):
    return len(audio) / sr < min_duration

def is_noisy(audio, threshold=0.4):
    zcr = librosa.feature.zero_crossing_rate(audio)
    return zcr.mean() > threshold

def validate_audio(audio, sr):
    if is_silent(audio):
        return False, "silence"
    if is_too_short(audio, sr):
        return False, "too short"
    if is_noisy(audio):
        return False, "too noisy"
    return True, "ok"

is_valid, reason = validate_audio(audio, sr)
print("Audio valid:", is_valid, "| Reason:", reason)

AUDIO_PATH = "/content/my_audio_happy.wav"

audio, sr = librosa.load(AUDIO_PATH, sr=16000)

print("Sample rate:", sr)
print("Duration (sec):", len(audio) / sr)

is_valid, reason = validate_audio(audio, sr)
print("Audio valid:", is_valid, "| Reason:", reason)

rms = librosa.feature.rms(y=audio)
print("RMS mean:", rms.mean())
print("RMS min:", rms.min())
print("RMS max:", rms.max())

"""## Распознавание эмоции по аудиосообщению

Эмоциональная окраска речи пользователя определяется на основе аудиосигнала
с использованием предобученной модели распознавания эмоций по речи.
"""

from transformers import pipeline

emotion_model = pipeline(
    "audio-classification",
    model="superb/hubert-large-superb-er"
)

emotion_result = emotion_model(
    {"array": audio, "sampling_rate": sr}
)

emotion_audio = emotion_result[0]["label"]
emotion_score = emotion_result[0]["score"]

print("Emotion:", emotion_audio)
print("Confidence:", round(emotion_score, 3))

"""## Нормализация аудиосигнала

Для повышения устойчивости распознавания речи выполняется нормализация
громкости аудиосигнала перед этапом Speech-to-Text.

"""

def normalize_audio(audio, target_rms=0.1):
    rms = np.sqrt(np.mean(audio**2))
    if rms == 0:
        return audio
    return audio * (target_rms / rms)

audio_norm = normalize_audio(audio)
sf.write("normalized.wav", audio_norm, sr)

"""## Преобразование речи в текст (Speech-to-Text)

Аудиосообщение пользователя преобразуется в текстовую форму для дальнейшего
семантического анализа.

"""

import whisper

whisper_model = whisper.load_model("small")

result = whisper_model.transcribe(
    "normalized.wav",
    language="ru",
    task="transcribe",
    condition_on_previous_text=False,
    temperature=0.0,
    no_speech_threshold=0.3
)

transcript = result["text"].strip().lower()

print("Transcript:")
print(transcript)

"""## Валидация результата распознавания речи

Текстовая транскрипция считается корректной, если содержит осмысленную
речь достаточной длины.
"""

def is_valid_transcript(text, min_words=2):
    return len(text.split()) >= min_words

print("Transcript valid:", is_valid_transcript(transcript))

"""## Итоговый результат обработки аудиосообщения"""

output = {
    "emotion_audio": emotion_audio,
    "transcript": transcript
}

output

"""Перед извлечением пользовательских предпочтений был проведён анализ музыкального датасета с целью определения допустимых категорий жанров и языков. Это позволило ограничить пространство возможных намерений пользователя только теми категориями, которые реально представлены в данных, и повысить согласованность между пользовательским запросом и этапом подбора музыкального контента.

Для извлечения жанровых предпочтений был сформирован словарь жанров на основе анализа распределения жанров в итоговом музыкальном датасете. Сырые жанровые теги были агрегированы в канонические жанровые классы (pop, rock, hip-hop, electronic и др.), отражающие реальные пользовательские формулировки. Извлечение жанра из пользовательского текста выполняется с помощью поиска ключевых слов и синонимов, что обеспечивает интерпретируемость и воспроизводимость метода.
"""

import pandas as pd

tracks = pd.read_csv(
    "tracks_with_language_FINAL.csv",
    encoding="utf-8-sig"
)

tracks.columns

import ast
from collections import Counter
import pandas as pd

all_genres = []

for g in tracks["genres"].dropna():
    if not isinstance(g, str):
        continue
    try:
        parsed = ast.literal_eval(g)
        if isinstance(parsed, list):
            all_genres.extend(parsed)
    except:
        pass

len(all_genres)

genre_counts = Counter(all_genres)

genres_df = (
    pd.DataFrame(
        genre_counts.items(),
        columns=["genre", "count"]
    )
    .sort_values("count", ascending=False)
    .reset_index(drop=True)
)

genres_df.head(30)

genres_df.to_csv(
    "all_genres_from_tracks_dataset.csv",
    index=False,
    encoding="utf-8-sig"
)

"""теперь нормализуем эти жанры"""

genres_df = pd.read_csv(
    "all_genres_from_tracks_dataset.csv",
    encoding="utf-8-sig"
)

genres_df.head()

def tokenize_genre(g):
    return (
        g.lower()
        .replace("-", " ")
        .replace("_", " ")
        .split()
    )

genres_df["tokens"] = genres_df["genre"].apply(tokenize_genre)

genres_df.to_csv(
    "all_genres_tokenized.csv",
    index=False,
    encoding="utf-8-sig"
)

"""Для извлечения жанровых предпочтений был сформирован набор из 20 канонических жанров. Словарь жанров был построен на основе анализа жанровых тегов итогового музыкального датасета. Сырые жанры были нормализованы и сопоставлены с каноническими классами, отражающими реальные пользовательские формулировки. Извлечение жанра из текста пользователя осуществляется на основе поиска ключевых токенов, что обеспечивает интерпретируемость и воспроизводимость метода."""

genres_df = pd.read_csv(
    "all_genres_tokenized.csv",
    encoding="utf-8-sig"
)

genres_df["tokens"] = genres_df["tokens"].apply(
    lambda x: ast.literal_eval(x) if isinstance(x, str) else x
)

genres_df.head()

STOP_TOKENS = {
    "russian", "canadian", "swedish", "german", "french",
    "latin", "korean", "japanese", "chinese", "british",
    "classic", "modern", "post", "neo", "new", "old",
}

GENRE_KEYWORDS = {
    # POP / MAINSTREAM
    "pop": {
        "pop", "поп"
    },
    "dance": {
        "dance", "танц"
    },
    "electronic": {
        "electronic", "edm", "house", "techno", "trance", "электрон", "хаус"
    },
    "indie": {
        "indie", "инди"
    },

    # HIP-HOP / URBAN
    "hip_hop": {
        "hip", "hop", "хип", "хоп"
    },
    "rap": {
        "rap", "рэп", "реп"
    },
    "trap": {
        "trap", "трэп", "треп"
    },
    "rnb": {
        "rnb", "r&b", "рнб"
    },

    # ROCK
    "rock": {
        "rock", "рок"
    },
    "metal": {
        "metal", "метал"
    },
    "punk": {
        "punk", "панк"
    },
    "alternative": {
        "alternative", "альтернатив"
    },

    # INSTRUMENTAL / ACADEMIC
    "classical": {
        "classical", "классик", "symphon", "orchestr", "оркест"
    },
    "instrumental": {
        "instrumental", "инструмент", "piano", "пиан"
    },
    "ambient": {
        "ambient", "эмбиент"
    },
    "jazz": {
        "jazz", "джаз"
    },

    # OTHER
    "folk": {
        "folk", "фолк"
    },
    "latin": {
        "latin", "латино"
    },
    "soundtrack": {
        "soundtrack", "саундтрек", "score"
    },
    "blues": {
        "blues", "блюз"
    },
}

import re

def extract_genre_intent(text: str):
    if not isinstance(text, str):
        return []

    text = text.lower()
    tokens = re.findall(r"\w+", text)

    found_genres = set()

    for genre, keywords in GENRE_KEYWORDS.items():
        for token in tokens:
            for kw in keywords:
                if token.startswith(kw):
                    found_genres.add(genre)
                    break

    return list(found_genres)

extract_genre_intent("включи русский рэп")

extract_genre_intent("поставь хип хоп")

extract_genre_intent("хочу инструментальную музыку")

extract_genre_intent("включи альтернативную инди музыку")

"""Извлечение жанровых намерений пользователя реализовано на основе правил и словарей ключевых слов. Для обработки морфологических вариаций русского языка используется сопоставление по основе слова (prefix matching), что позволяет корректно учитывать падежные формы без применения морфологического анализа. Словарь жанров включает 20 канонических классов, сформированных на основе анализа жанровых тегов итогового музыкального датасета и отражающих реальные пользовательские формулировки. Такой подход обеспечивает интерпретируемость и воспроизводимость метода.

Мы извлекаем 3 типа намерений:

language — ru / en / instrumental / other

genre — список из 20 канонических жанров

play_intent — есть ли явный запрос на воспроизведение
"""

GENRE_KEYWORDS = {
    # POP / MAINSTREAM
    "pop": {
        "pop", "поп"
    },
    "dance": {
        "dance", "танц"
    },
    "electronic": {
        "electronic", "edm", "house", "techno", "trance", "электрон", "хаус"
    },
    "indie": {
        "indie", "инди"
    },

    # HIP-HOP / URBAN
    "hip_hop": {
        "hip", "hop", "хип", "хоп"
    },
    "rap": {
        "rap", "рэп", "реп"
    },
    "trap": {
        "trap", "трэп", "треп"
    },
    "rnb": {
        "rnb", "r&b", "рнб"
    },

    # ROCK
    "rock": {
        "rock", "рок"
    },
    "metal": {
        "metal", "метал"
    },
    "punk": {
        "punk", "панк"
    },
    "alternative": {
        "alternative", "альтернатив"
    },

    # INSTRUMENTAL / ACADEMIC
    "classical": {
        "classical", "классик", "symphon", "orchestr", "оркест"
    },
    "instrumental": {
        "instrumental", "инструмент", "piano", "пиан"
    },
    "ambient": {
        "ambient", "эмбиент"
    },
    "jazz": {
        "jazz", "джаз"
    },

    # OTHER
    "folk": {
        "folk", "фолк"
    },
    "latin": {
        "latin", "латино"
    },
    "soundtrack": {
        "soundtrack", "саундтрек", "score"
    },
    "blues": {
        "blues", "блюз"
    },
}

LANGUAGE_KEYWORDS = {
    "ru": {"русск", "на русском", "русский"},
    "en": {"английск", "на английском", "english"},
    "instrumental": {"инструмент", "без слов", "без вокала"},
}

PLAY_KEYWORDS = {
    "включи", "поставь", "запусти", "проиграй",
    "хочу", "давай", "воспроизведи",
    "play", "start"
}

def tokenize(text: str):
    return re.findall(r"\w+", text.lower())

def extract_genre_intent(text: str):
    tokens = tokenize(text)
    found = set()

    for genre, keywords in GENRE_KEYWORDS.items():
        for token in tokens:
            for kw in keywords:
                if token.startswith(kw):
                    found.add(genre)
                    break

    return list(found)

def extract_language_intent(text: str):
    tokens = tokenize(text)

    for token in tokens:
        for kw in LANGUAGE_KEYWORDS["instrumental"]:
            if token.startswith(kw):
                return "instrumental"

    for lang in ["ru", "en"]:
        for token in tokens:
            for kw in LANGUAGE_KEYWORDS[lang]:
                if token.startswith(kw):
                    return lang

    return "other"

def extract_play_intent(text: str):
    tokens = tokenize(text)
    return any(token in PLAY_KEYWORDS for token in tokens)

def extract_user_intents(text: str):
    if not isinstance(text, str) or not text.strip():
        return {
            "language": "other",
            "genres": [],
            "play_intent": False
        }

    return {
        "language": extract_language_intent(text),
        "genres": extract_genre_intent(text),
        "play_intent": extract_play_intent(text)
    }

extract_user_intents("включи русский рэп")

extract_user_intents("хочу инструментальную музыку")

extract_user_intents("электронная музыка")

"""## Извлечение эмоции пользователя

Эмоциональное состояние пользователя определяется на основе аудиосигнала
до этапа распознавания речи. Для этого используется предварительно обученная
модель распознавания эмоций по аудио, которая анализирует акустические
характеристики сигнала и относит его к одному из фиксированных эмоциональных
классов.

Полученная эмоция далее используется как дополнительный семантический признак
при формировании пользовательского запроса и выборе музыкальных рекомендаций.

"""

EMOTION_CLASSES = {
    "happy",
    "sad",
    "calm",
    "angry",
    "energetic",
    "neutral"
}

def get_emotion_label(emotion):
    """
    Адаптер для эмоции.
    Принимает то, что уже вернула модель,
    и приводит к одному из фиксированных классов.
    """
    if emotion not in EMOTION_CLASSES:
        return "neutral"
    return emotion

LANGUAGE_KEYWORDS = {
    "ru": ["русск", "российск", "по-русск"],
    "instrumental": ["инструментал", "без слов", "фонов", "саундтрек"],
}

PLAY_KEYWORDS = [
    "включи", "поставь", "запусти", "хочу послушать", "проиграй"
]

def extract_user_intent(transcript, emotion_audio):
    return {
        "emotion": emotion_audio,
        "language": extract_language_intent(transcript),
        "genres": extract_genre_intent(transcript),
        "play_intent": extract_play_intent(transcript),
        "transcript": transcript
    }

def extract_language_intent(text):
    for lang, keys in LANGUAGE_KEYWORDS.items():
        if any(k in text for k in keys):
            return lang
    return None

user_intent = extract_user_intent(
    transcript=transcript,
    emotion_audio=emotion_audio
)

user_intent

"""то есть у нас есть словари намерения

______________________________________________________________
"""

import librosa
import numpy as np
import soundfile as sf
import whisper
from transformers import pipeline

emotion_model = pipeline(
    "audio-classification",
    model="superb/hubert-large-superb-er"
)

whisper_model = whisper.load_model("small")

def is_silent(audio, threshold=0.003, min_ratio=0.05):
    rms = librosa.feature.rms(y=audio)[0]
    speech_ratio = (rms > threshold).mean()
    return speech_ratio < min_ratio

def is_too_short(audio, sr, min_duration=1.0):
    return len(audio) / sr < min_duration

def is_noisy(audio, threshold=0.4):
    zcr = librosa.feature.zero_crossing_rate(audio)
    return zcr.mean() > threshold

def validate_audio(audio, sr):
    if is_silent(audio):
        return False, "silence"
    if is_too_short(audio, sr):
        return False, "too short"
    if is_noisy(audio):
        return False, "too noisy"
    return True, "ok"

LANGUAGE_KEYWORDS = {
    "ru": ["русск", "российск", "по-русск"],
    "instrumental": ["инструментал", "без слов", "фонов", "саундтрек"],
}

PLAY_KEYWORDS = [
    "включи", "поставь", "запусти", "проиграй", "хочу послушать"
]

GENRE_SYNONYMS = {
    # POP / MAINSTREAM
    "pop": {
        "pop", "поп"
    },
    "dance": {
        "dance", "танц"
    },
    "electronic": {
        "electronic", "edm", "house", "techno", "trance", "электрон", "хаус"
    },
    "indie": {
        "indie", "инди"
    },

    # HIP-HOP / URBAN
    "hip_hop": {
        "hip", "hop", "хип", "хоп"
    },
    "rap": {
        "rap", "рэп", "реп"
    },
    "trap": {
        "trap", "трэп", "треп"
    },
    "rnb": {
        "rnb", "r&b", "рнб"
    },

    # ROCK
    "rock": {
        "rock", "рок"
    },
    "metal": {
        "metal", "метал"
    },
    "punk": {
        "punk", "панк"
    },
    "alternative": {
        "alternative", "альтернатив"
    },

    # INSTRUMENTAL / ACADEMIC
    "classical": {
        "classical", "классик", "symphon", "orchestr", "оркест"
    },
    "instrumental": {
        "instrumental", "инструмент", "piano", "пиан"
    },
    "ambient": {
        "ambient", "эмбиент"
    },
    "jazz": {
        "jazz", "джаз"
    },

    # OTHER
    "folk": {
        "folk", "фолк"
    },
    "latin": {
        "latin", "латино"
    },
    "soundtrack": {
        "soundtrack", "саундтрек", "score"
    },
    "blues": {
        "blues", "блюз"
    },
}

def extract_language_intent(text):
    for lang, keys in LANGUAGE_KEYWORDS.items():
        if any(k in text for k in keys):
            return lang
    return None

def extract_genre_intent(text):
    found = []
    for genre, keys in GENRE_SYNONYMS.items():
        if any(k in text for k in keys):
            found.append(genre)
    return found

def extract_play_intent(text):
    return any(k in text for k in PLAY_KEYWORDS)

def process_audio_request(audio_path):
    audio, sr = librosa.load(audio_path, sr=16000)

    is_valid, reason = validate_audio(audio, sr)
    if not is_valid:
        return {
            "status": "invalid_audio",
            "reason": reason
        }

    emotion_result = emotion_model(
        {"array": audio, "sampling_rate": sr}
    )
    emotion_audio = emotion_result[0]["label"]
    emotion_confidence = emotion_result[0]["score"]

    rms = np.sqrt(np.mean(audio ** 2))
    if rms > 0:
        audio = audio * (0.1 / rms)

    sf.write("normalized.wav", audio, sr)

    stt_result = whisper_model.transcribe(
        "normalized.wav",
        language="ru",
        task="transcribe",
        condition_on_previous_text=False,
        temperature=0.0
    )

    transcript = stt_result["text"].strip().lower()

    intent = {
        "emotion": emotion_audio,
        "emotion_confidence": round(emotion_confidence, 3),
        "language": extract_language_intent(transcript),
        "genres": extract_genre_intent(transcript),
        "play_intent": extract_play_intent(transcript),
        "transcript": transcript
    }

    return {
        "status": "ok",
        "intent": intent
    }

result = process_audio_request("/content/my_audio_happy.wav")
result