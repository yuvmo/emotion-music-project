# Система по подбору музыки по голосовому сообщению пользователя

Дисциплина: "Мультимодальные модели: архитектуры, обучение и применение"
Студенты: Морозова Юлия Владимировна (telegram: @yumovl), Рябова Екатерина Юрьевна (telegram: @vydrzte)

---

## Описание проекта

Этот проект представляет собой систему, которая анализирует эмоциональную окраску голоса и содержание текстового содержимого в аудиосообщении и подбирает музыку, соответствующую определенному настроению. Пользователь записывает или загружает аудиофайл, система определяет одну из семи эмоций (злость, отвращение, страх, счастье, грусть, удивление, нейтральное состояние) и предлагает плейлист с треками из Spotify.

Для распознавания эмоций по речи используется модель `superb/hubert-large-superb-er`, по тексту - `cointegrated/rubert-tiny2-cedr-emotion-detection`, а для поиска музыки — датасет [Spotify Dataset 1921-2020, 160k+ Tracks](https://www.kaggle.com/datasets/yamaerenay/spotify-dataset-1921-2020-160k-tracks). Интерфейс приложения реализован с использованием `Streamlit`.

---

## Пайплайн проекта

1.  **Загрузка аудио:** Пользователь загружает аудиофайл в формате `.wav` или записывает его через микрофон прямо в интерфейсе приложения.
2.  **Предобработка аудио:** Загруженный аудиофайл преобразуется в массив и ресемплируется до 16000 Гц для соответствия требованиям модели.
3.  **Распознавание эмоций по голосу:** Обработанное аудио подается на вход модели `superb/hubert-large-superb-er` для определения эмоциональной окраски голоса.
4.  **Распознавание эмоций по тексту:** С помощью библиотеки `whisper` аудио преобразуется в текст, определяется эмоция.
5.  **Запрос GigaChat:** LLM анализирует какие характеристики свойствены той музыке, которая в текущем состоянии требуется пользователю.
6.  **Получение плейлиста:** На основе предсказанной эмоции система использует датасет для поиска и получения соответствующего плейлиста.
5.  **Отображение результата:** Пользователю отображается определенная эмоция и треки из него (со ссылкой на Spotify).

---

## Распределение результатов работы на 11.12

*   **Рябова Екатерина Юрьевна:**
    *   Исследование и выбор модели для распознавания эмоций в речи.
    *   Разработка скриптов для обработки аудиоданных и предсказания эмоций.
    *   EDA по датасету, для дальнейшего выбора фильтрации итоговых результатов.
    *   Сопоставление жанра трека и эмоции пользователя.

*   **Морозова Юлия Владимировна:**
    *   Исследование и выбор модели для задачи speech2text и распознавания эмоций по тексту.
    *   Интеграция с LLM для подбора нужных характеристик по эмоции пользователя.
    *   Разработка пользовательского интерфейса с помощью `Streamlit` (временное решение).
    *   Сборка и запуск демонстрации и тест работоспособности backend-части.
