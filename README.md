# Music Emotion Bot

Telegram-бот для подбора музыки на основе эмоций пользователя. Анализирует голосовые сообщения, определяет эмоциональное состояние и подбирает треки из датасета.

## Авторы

Разработано в рамках курса «Мультимодальные модели: архитектуры, обучение и применение», ВКонтакте.
Студенты группы ММОАД241С: 
Морозова Юлия Владимировна (telegram: @yumovl)
Рябова Екатерина Юрьевна (telegram: @vydrzte)

## Технологический стек

| Компонент | Технология |
|-----------|------------|
| Telegram Bot | aiogram 3.x |
| Speech-to-Text | OpenAI Whisper |
| Emotion Recognition | HuBERT (superb/hubert-large-superb-er) |
| LLM | GigaChat (langchain-gigachat) |
| Music Search | Spotify API (spotipy) |
| Data Processing | pandas, numpy, scikit-learn |

## Архитектура

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              TELEGRAM BOT                                   │
│                            (bot/handlers.py)                                │
└─────────────────────────────────┬───────────────────────────────────────────┘
                                  │ Voice Message
                                  ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                         MUSIC RECOMMENDATION PIPELINE                       │
│                              (src/pipeline.py)                              │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ Step 1: Audio Processing                                               │ │
│  │ ┌──────────────────────┐  ┌──────────────────────┐                     │ │
│  │ │   Whisper (STT)      │  │   HuBERT (Emotion)   │                     │ │
│  │ │   audio → text       │  │   audio → emotion    │                     │ │
│  │ └──────────────────────┘  └──────────────────────┘                     │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│                                    │                                        │
│                                    ▼                                        │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ Step 2: Intent Extraction                                              │ │
│  │ - Genres (pop, rock, rap, ...)                                         │ │
│  │ - Language (ru, en, instrumental)                                      │ │
│  │ - Mood keywords (веселый, грустный, энергичный, ...)                   │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│                                    │                                        │
│                                    ▼                                        │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ Step 3: GigaChat Analysis                                              │ │
│  │ - Mood interpretation                                                  │ │
│  │ - Audio features: valence, energy, danceability, acousticness, tempo   │ │
│  │ - Filters: genres, language, year, artist                              │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│                                    │                                        │
│                                    ▼                                        │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ Step 4: Music Recommendation                                           │ │
│  │ - Filter by artist (fuzzy matching + aliases)                          │ │
│  │ - Filter by language, genres, years                                    │ │
│  │ - Sort by feature distance (weighted Euclidean)                        │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
│                                    │                                        │
│                                    ▼                                        │
│  ┌────────────────────────────────────────────────────────────────────────┐ │
│  │ Step 5: Track Validation & Response                                    │ │
│  │ - Spotify verification (optional)                                      │ │
│  │ - GigaChat response generation                                         │ │
│  └────────────────────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────────────────────┘
```

## Структура проекта

```
emotion-music-project/
├── bot/                          # Telegram бот
│   ├── main.py                   # Точка входа, предзагрузка моделей
│   ├── handlers.py               # Обработчики сообщений и callback'ов
│   └── keyboards.py              # Клавиатуры и кнопки
│
├── config/
│   └── settings.py               # Конфигурация (API ключи, пути)
│
├── data/
│   ├── tracks_cleaned.csv        # Основной датасет (~290k треков)
│   ├── tracks_with_language_FINAL.csv  # Изначальный (резервный) датасет
│   ├── feedback.csv              # Фидбек пользователей
│   └── metrics.csv               # Метрики запросов
│
├── src/
│   ├── pipeline.py               # Главный пайплайн рекомендаций
│   │
│   ├── audio/                    # Модуль обработки аудио
│   │   ├── processor.py          # AudioProcessor: загрузка, транскрипция
│   │   ├── emotion.py            # AudioEmotionClassifier: HuBERT
│   │   └── validation.py         # Валидация аудио (тишина, шум, длина)
│   │
│   ├── intent/
│   │   └── extractor.py          # Извлечение намерений из текста
│   │
│   ├── llm/
│   │   ├── gigachat.py           # GigaChatService: анализ и генерация
│   │   └── prompts.py            # Промпты для LLM
│   │
│   ├── recommender/
│   │   └── music.py              # MusicRecommender: поиск треков
│   │
│   ├── spotify_client.py         # Клиент Spotify API
│   ├── track_validator.py        # Валидация и обогащение треков
│   ├── metrics.py                # Сбор метрик
│   └── utils.py                  # Утилиты (LLM wrapper)
│
├── scripts/
│   ├── clean_and_enrich_dataset.py  # Очистка датасета
│   └── analyze_metrics.py           # Анализ метрик
│
├── notebooks/                    # Jupyter notebooks для исследований
├── requirements.txt
└── README.md
```

## Технические параметры
### 1. Конфигурация

Файл `.env` в корне проекта:

```env
# Telegram
TELEGRAM_BOT_TOKEN=your_telegram_bot_token

# GigaChat
GIGACHAT_API_KEY=your_gigachat_api_key
DEFAULT_MODEL=GigaChat-2-Max

# Spotify (опционально)
SPOTIFY_CLIENT_ID=your_spotify_client_id
SPOTIFY_CLIENT_SECRET=your_spotify_client_secret

# Настройки
WHISPER_MODEL_SIZE=small
DEFAULT_TOP_K=5
LOG_LEVEL=INFO
```

### 2. Датасет

Датасет `tracks_cleaned.csv` должен находиться в директории `data/`. Файл содержит колонки:
- `spotify_id` — ID трека в Spotify
- `name` — название трека
- `artist_clean` — имя исполнителя
- `year` — год выпуска
- `genres` — список жанров (JSON)
- `language` — язык (ru/en/instrumental/other)
- `valence`, `energy`, `danceability`, `acousticness`, `tempo` — аудио-характеристики

## Запуск

При первом запуске загружаются модели Whisper и HuBERT (~1.5 GB).

## Использование

Телеграм-бот: @emotional_tracks_bot

1. Отправьте голосовое сообщение боту
2. Опишите желаемую музыку или своё настроение
3. Получите персонализированную подборку треков

**Примеры запросов:**
- «Хочу что-то весёлое»
- «Грустно, поставь русский рэп»
- «Включи Монеточку»
- «Нужна энергичная музыка для спорта»
- «Что-нибудь спокойное без слов»

## Ключевые особенности

### Распознавание эмоций
Используется модель HuBERT для определения эмоции в голосе:
- happy, sad, angry, neutral, energetic, calm, anxious

### Fuzzy-поиск артистов

**Зачем это нужно:** Whisper может неправильно транскрибировать имена артистов в голосовых сообщениях. Например, пользователь говорит "OG Buda", а Whisper распознаёт как "Оджибуда" или "О.Г. Буда". Без fuzzy-поиска система не найдёт треки этого артиста.

**Как работает:**
1. **Транслитерация** — кириллица → латиница ("Оджибуда" → "odzhbuda")
2. **Нормализация** — удаление пробелов, точек, дефисов ("О.Г. Буда" → "ogbuda")
3. **Расстояние Левенштейна** — подсчёт минимального количества изменений для превращения одной строки в другую
4. **Словарь алиасов** — предопределённые варианты написания популярных артистов

**Примеры:**
- Пользователь: "включи оджибуда" → система находит "OG Buda"
- Пользователь: "монетка" → система находит "Монеточка"

### Weighted Distance

**Зачем это нужно:** Когда пользователь просит "весёлую музыку" или "что-то энергичное", нужно найти треки, которые максимально соответствуют этим эмоциональным характеристикам. Weighted Distance позволяет ранжировать треки по степени соответствия целевым параметрам.

**Как работает:**
1. GigaChat определяет целевые значения: `valence=0.8, energy=0.7, danceability=0.6`
2. Для каждого трека вычисляется расстояние до целевых параметров:
   ```
   distance = √(w₁·(valence - target)² + w₂·(energy - target)² + ...)
   ```
3. Треки сортируются по возрастанию расстояния (меньше расстояние = лучше соответствие)

**Веса признаков:**
- `valence` (1.5) — самый важный для эмоционального соответствия
- `energy` (1.2) — важный для настроения
- `danceability` (1.0) — базовый вес
- `acousticness` (0.8) — менее важный
- `tempo` (0.5) — наименее важный (нормализуется делением на 140)

**Пример:** Если пользователь хочет "весёлую энергичную музыку", система найдёт треки с высоким `valence` и `energy`, даже если они не идеально подходят по другим параметрам.

### Метрики
Каждый запрос логируется в `data/metrics.csv`:
- Время обработки каждого этапа
- Распознанный текст и эмоция
- Извлечённые интенты
- Параметры LLM
- Количество найденных треков
